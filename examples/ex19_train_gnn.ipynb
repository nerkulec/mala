{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import mala\n",
    "from mala import printout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = mala.Parameters()\n",
    "\n",
    "# Currently, the splitting in training, validation and test set are\n",
    "# done on a \"by snapshot\" basis.\n",
    "parameters.data.data_splitting_type = \"by_snapshot\"\n",
    "parameters.data.use_graph_data_set = True\n",
    "\n",
    "# Specify the training parameters.\n",
    "parameters.running.max_number_epochs = 100\n",
    "parameters.running.ldos_grid_batch_size = 40\n",
    "parameters.running.learning_rate = 0.00001\n",
    "parameters.running.trainingtype = \"Adam\"\n",
    "\n",
    "parameters.targets.ldos_gridsize = 201\n",
    "parameters.verbosity = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data rescaling will be performed.\n",
      "No data rescaling will be performed.\n",
      "Checking the snapshots and your inputs for consistency.\n",
      "Consistency check successful.\n",
      "Data scalers already initilized, loading data to RAM.\n",
      "Build datasets.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12150/12150 [00:44<00:00, 272.38it/s]\n",
      "100%|██████████| 12150/12150 [00:44<00:00, 273.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build dataset: Done.\n"
     ]
    }
   ],
   "source": [
    "data_handler = mala.DataHandlerGraph(parameters)\n",
    "\n",
    "# for i in range(16):\n",
    "for i in range(1):\n",
    "    data_handler.add_raw_snapshot(\n",
    "        f'/bigdata/casus/wdm/Bartek_H2/H128/snapshot{i}/H_snapshot{i}.pw.scf.in',\n",
    "        f'/bigdata/casus/wdm/Bartek_H2/H128/ldos/H_snapshot{i}.out.npy',\n",
    "        (90, 90, 60, 201), 'tr'\n",
    "    )\n",
    "# for i in range(16, 20):\n",
    "for i in range(1, 2):\n",
    "    data_handler.add_raw_snapshot(\n",
    "        f'/bigdata/casus/wdm/Bartek_H2/H128/snapshot{i}/H_snapshot{i}.pw.scf.in',\n",
    "        f'/bigdata/casus/wdm/Bartek_H2/H128/ldos/H_snapshot{i}.out.npy',\n",
    "        (90, 90, 60, 201), 'va'\n",
    "    )\n",
    "\n",
    "data_handler.prepare_data(reparametrize_scaler=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters.network.nn_type = \"se3_transformer\"\n",
    "parameters.network.layer_sizes = [\n",
    "    data_handler.input_dimension,\n",
    "    64,\n",
    "    data_handler.output_dimension\n",
    "]\n",
    "\n",
    "# Setup network and trainer.\n",
    "network = mala.Network(parameters)\n",
    "# trainer = mala.Trainer(parameters, network, data_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() missing 1 required positional argument: 'grid_graph'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain_network()\n",
      "File \u001b[0;32m~/casus/mala/mala/network/trainer.py:223\u001b[0m, in \u001b[0;36mTrainer.train_network\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[39m############################\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[39m# CALCULATE INITIAL METRICS\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[39m############################\u001b[39;00m\n\u001b[1;32m    222\u001b[0m tloss \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39minf\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 223\u001b[0m vloss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__validate_network(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnetwork,\n\u001b[1;32m    224\u001b[0m                                 \u001b[39m\"\u001b[39;49m\u001b[39mvalidation\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    225\u001b[0m                                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparameters\u001b[39m.\u001b[39;49m\n\u001b[1;32m    226\u001b[0m                                 after_before_training_metric)\n\u001b[1;32m    228\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mtest_data_sets:\n\u001b[1;32m    229\u001b[0m     tloss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__validate_network(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnetwork,\n\u001b[1;32m    230\u001b[0m                                     \u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    231\u001b[0m                                     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparameters\u001b[39m.\u001b[39m\n\u001b[1;32m    232\u001b[0m                                     after_before_training_metric)\n",
      "File \u001b[0;32m~/casus/mala/mala/network/trainer.py:824\u001b[0m, in \u001b[0;36mTrainer.__validate_network\u001b[0;34m(self, network, data_set_type, validation_type)\u001b[0m\n\u001b[1;32m    822\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparameters\u001b[39m.\u001b[39m_configuration[\u001b[39m\"\u001b[39m\u001b[39mdevice\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    823\u001b[0m y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparameters\u001b[39m.\u001b[39m_configuration[\u001b[39m\"\u001b[39m\u001b[39mdevice\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m--> 824\u001b[0m prediction \u001b[39m=\u001b[39m network(x)\n\u001b[1;32m    825\u001b[0m validation_loss_sum \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \\\n\u001b[1;32m    826\u001b[0m     network\u001b[39m.\u001b[39mcalculate_loss(prediction, y)\u001b[39m.\u001b[39mitem()\n\u001b[1;32m    827\u001b[0m batchid \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/casus/mala-venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() missing 1 required positional argument: 'grid_graph'"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "trainer = pl.Trainer(gpus=1, max_epochs=10)\n",
    "trainer.fit(network, data_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
